#  Add precursor
prec_mz = as.numeric(fData(dat1)[i,1])
valid1 = which(masslist<(prec_mz+1))
masslist = masslist[valid1]
ppm_prec = min(ppm_calc(masslist, prec_mz))
if (ppm_prec > ppm_error){
masslist= c(masslist, prec_mz) # Add precursor peak by exact mass
}
#  Calculate mass diff
massdiff = unique(as.numeric(dist(masslist)))
massdiff = massdiff[massdiff>=30]
# Search
selected_index = search_rules(rules_feature, rules_type, masslist, massdiff, ppm_error)
decoy_index = search_rules(decoy_feature, decoy_type, masslist, massdiff, ppm_error)
if (length(selected_index)>0){
rules_extracted = rules[selected_index,]
decoy_extracted = decoy[decoy_index,]
# FDR
fdr_summmary = fdr_compute(rules_extracted, decoy_extracted, fdr_th)
thr1 = fdr_summmary$mcc_min
thr2 = fdr_summmary$lift_min
valid=which(rules_extracted$MCC>=thr1 & rules_extracted$LIFT>=thr2)
if (length(valid)>=1){
rules_extracted = rules_extracted[valid,]}
# Aggregate
rules_aggregated = aggregate_rules(rules_extracted)
RER = eval_rules_aggregated(rules_aggregated, "SUM", "LIFT", filter)
substructure_estimated = RER$SUBSTRUCTURE
# Compare to theoritical
substructure_theo= read.table(paste0(path, fData(dat1)$ID[i],"_substructure.txt"), sep="\t", header=F)[,1]
#compare = compute_similariy(substructure_estimated, substructure_theo)
compare = match(substructure_estimated, substructure_theo)
print(sum(!is.na(compare)))
}
}
i=108
dat1 = readMgfData("CASMI_2017_Positive.mgf", verbose =T)
#dat1 = readMgfData("CASMI_2017_Positive.mgf", verbose =T)
N1 = length(dat1)
for (i in 1:N1){
print(i)
masslist = dat1[[i]]@mz
#  Add precursor
prec_mz = as.numeric(fData(dat1)[i,1])
valid1 = which(masslist<(prec_mz+1))
masslist = masslist[valid1]
ppm_prec = min(ppm_calc(masslist, prec_mz))
if (ppm_prec > ppm_error){
masslist= c(masslist, prec_mz) # Add precursor peak by exact mass
}
#  Calculate mass diff
massdiff = unique(as.numeric(dist(masslist)))
massdiff = massdiff[massdiff>=30]
# Search
selected_index = search_rules(rules_feature, rules_type, masslist, massdiff, ppm_error)
decoy_index = search_rules(decoy_feature, decoy_type, masslist, massdiff, ppm_error)
if (length(selected_index)>0){
rules_extracted = rules[selected_index,]
decoy_extracted = decoy[decoy_index,]
# FDR
fdr_summmary = fdr_compute(rules_extracted, decoy_extracted, fdr_th)
thr1 = fdr_summmary$mcc_min
thr2 = fdr_summmary$lift_min
valid=which(rules_extracted$MCC>=thr1 & rules_extracted$LIFT>=thr2)
if (length(valid)>=1){
rules_extracted = rules_extracted[valid,]}
# Aggregate
rules_aggregated = aggregate_rules(rules_extracted)
RER = eval_rules_aggregated(rules_aggregated, "SUM", "MCC", filter)
substructure_estimated = RER$SUBSTRUCTURE
# Compare to theoritical
substructure_theo= read.table(paste0(path, fData(dat1)$ID[i],"_substructure.txt"), sep="\t", header=F)[,1]
#compare = compute_similariy(substructure_estimated, substructure_theo)
compare = match(substructure_estimated, substructure_theo)
print(sum(!is.na(compare)))
}
}
path="Ref_Substructures/"
ppm_error = 20
fdr_th = 11
filter = 1
dat1 = readMgfData("CASMI_2017_Positive.mgf", verbose =T)
#dat1 = readMgfData("CASMI_2017_Positive.mgf", verbose =T)
N1 = length(dat1)
for (i in 1:N1){
print(i)
masslist = dat1[[i]]@mz
#  Add precursor
prec_mz = as.numeric(fData(dat1)[i,1])
valid1 = which(masslist<(prec_mz+1))
masslist = masslist[valid1]
ppm_prec = min(ppm_calc(masslist, prec_mz))
if (ppm_prec > ppm_error){
masslist= c(masslist, prec_mz) # Add precursor peak by exact mass
}
#  Calculate mass diff
massdiff = unique(as.numeric(dist(masslist)))
massdiff = massdiff[massdiff>=30]
# Search
selected_index = search_rules(rules_feature, rules_type, masslist, massdiff, ppm_error)
decoy_index = search_rules(decoy_feature, decoy_type, masslist, massdiff, ppm_error)
if (length(selected_index)>0){
rules_extracted = rules[selected_index,]
decoy_extracted = decoy[decoy_index,]
# FDR
fdr_summmary = fdr_compute(rules_extracted, decoy_extracted, fdr_th)
thr1 = fdr_summmary$mcc_min
thr2 = fdr_summmary$lift_min
valid=which(rules_extracted$MCC>=thr1 & rules_extracted$LIFT>=thr2)
if (length(valid)>=1){
rules_extracted = rules_extracted[valid,]}
# Aggregate
rules_aggregated = aggregate_rules(rules_extracted)
RER = eval_rules_aggregated(rules_aggregated, "SUM", "MCC", filter)
substructure_estimated = RER$SUBSTRUCTURE
# Compare to theoritical
substructure_theo= read.table(paste0(path, fData(dat1)$ID[i],"_substructure.txt"), sep="\t", header=F)[,1]
#compare = compute_similariy(substructure_estimated, substructure_theo)
compare = match(substructure_estimated, substructure_theo)
print(sum(!is.na(compare)))
}
}
compare = fn(substructure_estimated, substructure_theo)
compare
substructure_estimated
substructure_theo
library(proxy)
compare = proxy::dist(substructure_estimated, substructure_theo, fn)
compare
head(compare)
compare[11,]
compare[11,]
compute_similariy(substructure_estimated, substructure_theo)
substructure_estimated[1]
substructure_estimated[2]
substructure_estimated[4]
substructure_theo[1]
substructure_theo[2]
theo= substructure_theo[11]
theo
compare = compute_similariy(substructure_estimated, theo)
candidates = substructure_estimated
candidates_finger <- lapply(parse.smiles(candidates), get.fingerprint, type='maccs')
compare = proxy::dist(substructure_estimated, substructure_theo, fn)
apply(compare,1,min)
apply(compare,1,max)
apply(compare,2,min)
substructure_theo
v
substructure_estimated
get.fingerprint(parse.smiles(substructure_estimated[1])[[1]],type='maccs')
xfinger =  get.fingerprint(parse.smiles(substructure_estimated[1])[[1]],type='maccs')
yfinger =  get.fingerprint(parse.smiles(substructure_estimated[2])[[1]],type='maccs')
1-distance(x_finger,y_finger)
1-distance(xfinger,yfinger)
distance(xfinger,yfinger)
apply(compare,2,min)
dim(compare)
length(substructure_estimated
)
length(substructure_theo)
summary(compare)
min(compare)
max(compare)
compare = proxy::dist(substructure_estimated, substructure_theo, method = "fn")
compare = proxy::dist(substructure_estimated, substructure_theo, method = fn)
compare[1,1]
compare[1,4]
compare[5323,4]
compare[532,4]
compare[2,523]
xfinger
yfinger
class(xfinger)
fp.distance=1-distance(xfinger,yfinger)
fp.distance
substructure_estimated[1]
substructure_theo[1]
substructure_theo[6]
compare = c()
for (x in substructure_theo){
dis_list = c()
for (y in substructure_estimated){
x_finger <- try(get.fingerprint(parse.smiles(x)[[1]],type='maccs'),silent=T)
y_finger <-  try(get.fingerprint(parse.smiles(y)[[1]],type='maccs'),silent=T)
if ((class(x_finger)!="try-error") && (class(y_finger)!="try-error")){
dis_list= c(dis_list, 1-distance(x_finger,y_finger))}
compare = c(compare, min(dis_list))
}
}
compare
len(substructure_theo)
length(substructure_theo)
min(compare)
compare = c()
for (x in substructure_theo){
dis_list = c()
for (y in substructure_estimated){
x_finger <- try(get.fingerprint(parse.smiles(x)[[1]],type='maccs'),silent=T)
y_finger <-  try(get.fingerprint(parse.smiles(y)[[1]],type='maccs'),silent=T)
if ((class(x_finger)!="try-error") && (class(y_finger)!="try-error")){
dis_list= c(dis_list, 1-distance(x_finger,y_finger))}}
compare = c(compare, min(dis_list))
}
compare
min(compare)
compare = match(toupper(substructure_estimated), toupper(substructure_theo))
compare
path="Ref_Substructures/"
ppm_error = 20
fdr_th = 11
filter = 1
dat1 = readMgfData("CASMI_2017_Positive.mgf", verbose =T)
#dat1 = readMgfData("CASMI_2017_Positive.mgf", verbose =T)
N1 = length(dat1)
for (i in 1:N1){
print(i)
masslist = dat1[[i]]@mz
#  Add precursor
prec_mz = as.numeric(fData(dat1)[i,1])
valid1 = which(masslist<(prec_mz+1))
masslist = masslist[valid1]
ppm_prec = min(ppm_calc(masslist, prec_mz))
if (ppm_prec > ppm_error){
masslist= c(masslist, prec_mz) # Add precursor peak by exact mass
}
#  Calculate mass diff
massdiff = unique(as.numeric(dist(masslist)))
massdiff = massdiff[massdiff>=30]
# Search
selected_index = search_rules(rules_feature, rules_type, masslist, massdiff, ppm_error)
decoy_index = search_rules(decoy_feature, decoy_type, masslist, massdiff, ppm_error)
if (length(selected_index)>0){
rules_extracted = rules[selected_index,]
decoy_extracted = decoy[decoy_index,]
# FDR
fdr_summmary = fdr_compute(rules_extracted, decoy_extracted, fdr_th)
thr1 = fdr_summmary$mcc_min
thr2 = fdr_summmary$lift_min
valid=which(rules_extracted$MCC>=thr1 & rules_extracted$LIFT>=thr2)
if (length(valid)>=1){
rules_extracted = rules_extracted[valid,]}
# Aggregate
rules_aggregated = aggregate_rules(rules_extracted)
RER = eval_rules_aggregated(rules_aggregated, "SUM", "MCC", filter)
substructure_estimated = RER$SUBSTRUCTURE
# Compare to theoritical
substructure_theo= read.table(paste0(path, fData(dat1)$ID[i],"_substructure.txt"), sep="\t", header=F)[,1]
# Compare list of candidates
#compare = c()
#for (x in substructure_estimated){
#  dis_list = c()
#  for (y in substructure_theo){
#      x_finger <- try(get.fingerprint(parse.smiles(x)[[1]],type='maccs'),silent=T)
#      y_finger <-  try(get.fingerprint(parse.smiles(y)[[1]],type='maccs'),silent=T)
#      if ((class(x_finger)!="try-error") && (class(y_finger)!="try-error")){
#        dis_list= c(dis_list, 1-distance(x_finger,y_finger))}}
#  compare = c(compare, min(dis_list))
#}
compare = match(toupper(substructure_estimated), toupper(substructure_theo))
print(sum(!is.na(compare)))
} else {print("No substructure found!")}
}
compare = match(toupper(substructure_estimated), toupper(substructure_theo))
compare
RER
i=108
print(i)
masslist = dat1[[i]]@mz
#  Add precursor
prec_mz = as.numeric(fData(dat1)[i,1])
valid1 = which(masslist<(prec_mz+1))
masslist = masslist[valid1]
ppm_prec = min(ppm_calc(masslist, prec_mz))
if (ppm_prec > ppm_error){
masslist= c(masslist, prec_mz) # Add precursor peak by exact mass
}
#  Calculate mass diff
massdiff = unique(as.numeric(dist(masslist)))
massdiff = massdiff[massdiff>=30]
selected_index = search_rules(rules_feature, rules_type, masslist, massdiff, ppm_error)
decoy_index = search_rules(decoy_feature, decoy_type, masslist, massdiff, ppm_error)
rules_extracted = rules[selected_index,]
decoy_extracted = decoy[decoy_index,]
fdr_summmary = fdr_compute(rules_extracted, decoy_extracted, fdr_th)
thr1 = fdr_summmary$mcc_min
thr2 = fdr_summmary$lift_min
valid=which(rules_extracted$MCC>=thr1 & rules_extracted$LIFT>=thr2)
valid
rules_extracted = rules_extracted[valid,]
View(rules_extracted)
rules_aggregated = aggregate_rules(rules_extracted)
RER = eval_rules_aggregated(rules_aggregated, "SUM", "MCC", filter)
substructure_estimated = RER$SUBSTRUCTURE[1:10]
substructure_estimated
substructure_theo= read.table(paste0(path, fData(dat1)$ID[i],"_substructure.txt"), sep="\t", header=F)[,1]
compare = match(toupper(substructure_estimated), toupper(substructure_theo))
print(sum(!is.na(compare)))
library(MergeION)
setwd("C:/Users/Liu/Desktop/MESSAR/3_MESSAR_TESTING/TESTING_R")
dat1 = readMgfData("MASSBANK_merged.mgf", verbose =T)
library(MergeION)
fData(dat1)
fdata(dat1)
library(MSnbase)
dat1 = readMgfData("MASSBANK_merged.mgf", verbose =T)
fData(dat1)
visualize.spectra("MASSBANK_merged.mgf","MASSBANK_4")
setwd("C:/Users/Liu/Desktop/MESSAR/4_WEBSERVER/MESSAR_WEBSERVER_RAW")
shiny::runApp()
runApp('C:/Users/Liu/Desktop/MESSAR/4_WEBSERVER/MESSAR_WEBSERVER_RAW_AUTOMATIC_FDR')
shiny::runApp()
setwd("C:/Users/Liu/Desktop/MESSAR/4_WEBSERVER/MESSAR_WEBSERVER_RAW_AUTOMATIC_FDR")
runApp()
runApp()
runApp()
runApp()
quantile(1:5,0)
x <- stats::runif(12); y <- stats::rnorm(12)
i <- order(x, y); x <- x[i]; y <- y[i]
plot(x,y, main = "arrows(.) and segments(.)")
## draw arrows from point to point :
s <- seq(length(x)-1)  # one shorter than data
arrows(x[s], y[s], x[s+1], y[s+1], col = 1:3)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
as.numeric(dist(1:4))
data.matrix(dist(1:4))
load("C:/Users/Liu/Desktop/MESSAR/4_WEBSERVER/MESSAR_WEBSERVER_RAW_AUTOMATIC_FDR/rule_db_multiple_sub_raw.RData")
tmp=aggregate_rules(rules)
runApp()
setwd("C:/Users/Liu/Desktop/MESSAR/4_WEBSERVER/MESSAR_WEBSERVER_RAW_AUTOMATIC_FDR")
runApp()
load("C:/Users/Liu/Desktop/MESSAR/4_WEBSERVER/MESSAR_WEBSERVER_RAW_AUTOMATIC_FDR/tmp.Rdata")
View(rules_aggregated)
setwd("C:/Users/Liu/Desktop/MESSAR/4_WEBSERVER/MESSAR_WEBSERVER_RAW_AUTOMATIC_FDR")
rules_aggregated$type
head(rules_aggregated$type)
rules_aggregated$type[1]
rules_aggregated$type[2]
rules_aggregated$type[3]
rules_aggregated$type[4]
rules_aggregated$features[4]
rules_aggregated$sum_aggregated
rules_aggregated$sum_aggregated$SUBSTRUCTURE
selected=2
rule_types = rules_aggregated$features[selected]
rule_features = rules_aggregated$features[selected]
rule_types
rule_features
i=18
rule_features = rules_aggregated$features[selected]
rule_features
i=3
selected=3
rule_types = rules_aggregated$features[selected]
rule_features = rules_aggregated$features[selected]
rule_types
rule_features
rule_types = rules_aggregated$type[selected]
rule_features = rules_aggregated$features[selected]
rule_types
rule_features
rule_types = strsplit(rule_types,",")[[1]]
rule_types
rule_types2 = strsplit("mass",",")[[1]]
rule_types2
rule_features = strsplit(rule_features,",")[[1]]
rule_features
rule_features = rules_aggregated$features[selected]
rule_features = as.numeric(strsplit(rule_features,",")[[1]])
rule_features
rule_fragments = rule_features[rule_types=="mass"]
ppm_search=20
rule_features
rules_aggregated$features
rules_aggregated$type
rules_aggregated$type[123]
rules_aggregated$type[124]
selected=124
selected = which(rules_aggregated$sum_aggregated$SUBSTRUCTURE==selected_substructures())[1]
rule_types = rules_aggregated$type[selected] # Features behind the selected rule
rule_features = rules_aggregated$features[selected]
rule_types
rule_features
rule_mdiff = rule_features[rule_types=="mass_diff"]
rule_mdiff
rule_types
rule_types = strsplit(rule_types,",")[[1]]
rule_features = as.numeric(strsplit(rule_features,",")[[1]])
rule_mdiff = rule_features[rule_types=="mass_diff"]
rule_mdiff
rule_mdiff = unique(rule_mdiff)
dist_mass = data.matrix(dist(1:5))
mdiff= rule_mdiff
errors = (dist_mass-mdiff)/mdiff*1000000
errors
errors = abs((dist_mass-mdiff)/mdiff*1000000)
errors
valid = which(errors<100000000000000000, arr.ind = T)
valid = which(errors<923123.2, arr.ind = T)
valid
sort(1:5, decreasing = T)
nrow(valid)
valid[1,]
as.numeric(valid[1,])
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
plot(1:5, 1:5,type="h")
plot(1:5, 1:5,type="h",col=c("red","green"))
plot(1:5, 1:5,type="h",col=c("red","green","green", "green","red"))
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
R=list(c(1,0),1:2)
R
as.numeric(sapply(R,function(x) x[1]))
as.numeric(sapply(R,function(x) x[2]))
all(sapply(R,length))
all(sapply(R,length)==1)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
sqrt(0)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
s=NULL
nrow(s)
runApp()
match(1:2,1:5)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
shiny::runApp('C:/Users/Liu/Desktop/MESSAR/5_Article/messar_code/MESSAR_WEBSERVER')
setwd("C:/Users/Liu/Desktop/MESSAR/5_Article/messar_code/MESSAR_WEBSERVER")
runApp()
runApp()
runApp()
runApp()
shiny::runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
